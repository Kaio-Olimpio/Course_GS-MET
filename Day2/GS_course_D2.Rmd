---
title: |
  ![](GenMelhor.png){width=10%}

  Genomic selection in multiple environments
author: 
  - Kaio Olimpio das Graças Dias, professor^[Federal University of Viçosa, kaio.o.dias@ufv.br]
  
  - Saulo Fabrício da Silva Chaves, Ph.D. student^[Federal University of Viçosa, saulo.chaves@ufv.br]
  
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    highlight: haddock
    includes:
      in_header: cabecalho.html
bibliography: references.bib
csl: apa.csl   
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

<br>

<br>

Yesterday, we learned how to perform the genomic selection in a single environment. Today, we will expand the models to a multiple-environment context.

To perform the analyses, we will need the following packages:

```{r echo=TRUE, warning=FALSE,eval=FALSE}
require(RCurl)
require(data.table)
require(AGHmatrix)
require(rrBLUP)
require(BGLR)
require(tidyverse)
require(ComplexHeatmap)
require(cvTools)
require(patchwork)
```

```{r echo=FALSE, warning=FALSE,include=FALSE}
library(kableExtra)
require(RCurl)
require(data.table)
require(AGHmatrix)
require(rrBLUP)
require(BGLR)
require(tidyverse)
require(ComplexHeatmap)
require(patchwork)
require(cvTools)
```

<br>

## Data

We will use the same data set as yesterday. Recall that the  data are available online at this [Github page](https://github.com/samuelbfernandes/Trait-assisted-GS) [@fernandes_efficiency_2018].

```{r echo=TRUE}
pheno = read.csv("https://raw.githubusercontent.com/samuelbfernandes/Trait-assisted-GS/master/means.csv")
pheno$GENO = as.factor(pheno$GENO)
pheno$LOC = as.factor(pheno$LOC)

```

In this case, we will use the whole data set. Note that the environments differ regarding the number of evaluated genotypes:

```{r echo=FALSE}
pheno %>% group_by(LOC) %>% summarise(length(GENO)) %>% kbl(escape = F, align = 'c', col.names = c("Environments","Number of genotypes")) %>% 
  kable_classic("hover",full_width = F, position="center", fixed_thead = T)

```

Note also that some genotypes were not evaluated in all the environments:

```{r echo=TRUE}

genmat = model.matrix(~-1+GENO, data = pheno)
envmat = model.matrix(~-1+LOC, data = pheno)
genenvmat = t(envmat) %*% genmat
genenvmat_ch = ifelse(genenvmat == 1, "Present", "Abscent")
Heatmap(genenvmat_ch, col = c("white","tomato"), show_column_names = F,
        heatmap_legend_param = list(title = ""),
        column_title = "Genotypes", row_title = "Environments")

```

In the Heatmap above, each column represents a genotype. The column is red if the genotype is present in an environment (in the rows), or red if it is absent.

We can also see how many genotypes we have in common between the environments:

```{r echo=TRUE, include=FALSE}
genenvmat %*% t(genenvmat)
```

```{r echo=FALSE}
genenvmat %*% t(genenvmat) %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = F, position="center", fixed_thead = T)
```

In the matrix above, the diagonal represents the number of genotypes in the j-th environment and off-diagonal is the number of common genotypes between the j-th and the j'-th environments.

The distribution of frequencies regarding the evaluated trait (grain yield) in all the environments is also similar to the gaussian distribution:

```{r echo=TRUE, warning=FALSE}
ggplot(pheno, aes(x = Y)) +  
  geom_histogram(aes(y = ..density..), bins = 30, 
                 colour = "black", fill = "steelblue") +
  geom_density(alpha = .7, size = 1.5, colour = "tomato") +
  labs(x = NULL, title = "Grain Yield",y="Density")
```

<br>

Now that we loaded and visualized the phenotypic data, we will load the genomic data. Here, we will also use the whole matrix:

```{r echo=TRUE,warning=FALSE}
SNPs = fread("https://raw.githubusercontent.com/samuelbfernandes/Trait-assisted-GS/master/snps.csv")
names_lines = SNPs[,1]
SNPs = SNPs[,-1]
SNPs = as.matrix(SNPs[1:dim(SNPs)[1], 1:dim(SNPs)[2]])
rownames(SNPs) = names_lines$V1
dim(SNPs)

```

```{r echo=TRUE,eval=FALSE}
SNPs[1:5,1:5]

```

```{r echo=FALSE,include=TRUE}
SNPs[1:5,1:5] %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = T, position="center", fixed_thead = T) %>% footnote("Dimension: 453 $\\times$ 58960",general_title = "")

```

<br>

<br>


## Building the G matrix

Recall that we can change the SNPs codification to a dosage solution by simply summing the matrix's elements by one:

```{r echo=TRUE,warning=FALSE}
SNPs = SNPs + 1
```

```{r echo=TRUE,eval=FALSE}
SNPs[1:5,1:5]
```

```{r echo=FALSE,include=TRUE}
SNPs[1:5,1:5] %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = T, position="center", fixed_thead = T)

```

Again, we will use the [AGHmatrix](https://cran.r-project.org/web/packages/AGHmatrix/vignettes/Tutorial_AGHmatrix.html) package [@amadeu_aghmatrix_2016] to build the G matrix:

```{r echo=TRUE, warning=FALSE}
G_matrix = Gmatrix(SNPs, method = "VanRaden", ploidy = 2, missingValue = NA)
```

Now we have the whole G matrix (453 x 453), which we can represent using a heatmap:

```{r echo=TRUE}

Heatmap(G_matrix, show_row_names = F, show_column_names = F,
        heatmap_legend_param = list(title = "Res"))

```

"Res" in the heatmap legend title is for "Resemblance". 

<br>

<br>

## Genomic selection

For all the multi-environment genomic analyses, we will use the [BGLR](https://github.com/gdlc/BGLR-R) package [@BGLR]. Here, we will illustrate an analysis using the Bayesian Ridge Regression, but the reader may employ different methods by changing the model term in the ETA. Indeed, the only difference between the multiple-environment and the single-environment genomic selection using BGLR is in the ETA. This is because we have to build the matrices of the other effects of the model besides the marker effects. The step-by-step below is inspired by the script that @persa_development_2021 made available.

### 1. Restraining the phenotypic data - only phenotyped and genotyped:

```{r echo=TRUE}
length(levels(pheno$GENO))
pheno = droplevels(pheno[pheno$GENO %in% rownames(SNPs), ])
length(levels(pheno$GENO))

```

<br>


### 2. Building the genotype and environment design matrices:

```{r echo=TRUE}

envmat = model.matrix(~-1+LOC, data = pheno)
```

```{r echo=FALSE}
envmat[1:5,1:3] %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = F, position="center", fixed_thead = T) %>% footnote("Dimension: 1002 $\\times$ 3",general_title = "")
```

```{r echo=TRUE}
genmat = model.matrix(~-1+GENO, data = pheno)
```

```{r echo=FALSE}
genmat[1:5,1:5] %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = F, position="center", fixed_thead = T) %>% footnote("Dimension: 1002 $\\times$ 453",general_title = "")
```

<br>

### 3. Building the environmental and genetic covariance matrices:

```{r echo=TRUE}

G = tcrossprod(tcrossprod(genmat,G_matrix),genmat)

```

```{r echo=FALSE}
G[1:5,1:5] %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = F, position="center", fixed_thead = T) %>% footnote("Dimension: 1002 $\\times$ 1002",general_title = "")
```


```{r echo=TRUE}
E = tcrossprod(envmat)
```

```{r echo=FALSE}
E[1:5,1:5] %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = F, position="center", fixed_thead = T) %>% footnote("Dimension: 1002 $\\times$ 1002",general_title = "")
```

<br>

### 4. Building the interaction matrix:

```{r echo=TRUE}

GE = G * E

```

```{r echo=FALSE}
GE[1:5,1:5] %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = F, position="center", fixed_thead = T) %>% footnote("Dimension: 1002 $\\times$ 1002",general_title = "")
```

<br>


### 5. Setting the linear predictors and the priors (ETA)

```{r echo=TRUE, warning=FALSE}
ETA = list(list(X = E, model = "FIXED"),
           list(X = G, model = "BRR"),
           list(X = GE, model = "BRR"))

```

<br>

### 6. Running the model

```{r echo=TRUE, warning=FALSE}
BRR = BGLR(y = pheno$Y,ETA = ETA, nIter = 30000, burnIn = 1000, 
           thin = 5, verbose = F)

BRR_GENO = data.frame("Genotype" = pheno$GENO,
                      "Environment" = pheno$LOC,
                      "Yield" = pheno$Y,
                      "GEBV" = BRR$yHat)

BRR_GENO %>% ggplot(aes(x = Yield, y = GEBV))+
  geom_point()+
  labs(caption = paste("Accuracy of prediction =", 
                       round(cor(BRR$yHat,
                                 pheno$Y,use = "complete.obs"),4)))

parvar = data.frame(
  'Parameter' = c("E","G","GE","e"),
  'Variance' = c(BRR$ETA[[1]]$varB, BRR$ETA[[2]]$varB, BRR$ETA[[3]]$varB, BRR$varE)
)

```

```{r echo=FALSE}

parvar %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = T, position="center", fixed_thead = T)

```

<br>


<br>

## Genomic selection - Using eigenvalues

The user may provide the eigenvalues of the covariance matrices that we built in the last topic:

```{r echo=TRUE}

G = tcrossprod(tcrossprod(genmat,G_matrix),genmat)
E = tcrossprod(envmat)
GE = G * E

EVD_G = eigen(G)
EVD_GE = eigen(GE)

```

This action is useful for optimizing the computational time. After obtaining the eigenvalues (and the eigenvectors), we can insert them in the ETA component, substituting the covariance matrices. In that case, we will no longer use the BRR method. Instead, we will use the Reproducing Kernel Hilbert Spaces (RKHS) regressions, which uses the eigenvalues to perform the analyses

```{r echo=TRUE, warning=FALSE}
ETA = list(list(X = E, model = "FIXED"),
           list(V = EVD_G$vectors, d = EVD_G$values, model = "RKHS"),
           list(V = EVD_GE$vectors, d = EVD_GE$values, model = "RKHS"))

```

After defining the ETA, we can fit the model:

```{r echo=TRUE, warning=FALSE}
RKHS = BGLR(y = pheno$Y,ETA = ETA, nIter = 30000, burnIn = 1000, 
           thin = 5, verbose = F)

RKHS_GENO = data.frame("Genotype" = pheno$GENO,
                      "Environment" = pheno$LOC,
                      "Yield" = pheno$Y,
                      "GEBV" = RKHS$yHat)

RKHS_GENO %>% ggplot(aes(x = Yield, y = GEBV))+
  geom_point()+
  labs(caption = paste("Accuracy of prediction =", 
                       round(cor(RKHS$yHat,
                                 pheno$Y,use = "complete.obs"),4)))

parvar = data.frame(
  'Parameter' = c("E","G","GE","e"),
  'Variance' = c(RKHS$ETA[[1]]$varB, RKHS$ETA[[2]]$varU, RKHS$ETA[[3]]$varU, RKHS$varE)
)

```

```{r echo=FALSE}
data.frame(
  'Parameter' = c("E","G","GE","e"),
  'Variance' = c(RKHS$ETA[[1]]$varB, RKHS$ETA[[2]]$varU, RKHS$ETA[[3]]$varU, RKHS$varE)
) %>% kbl(escape = F, align = 'c') %>% 
  kable_classic("hover",full_width = T, position="center", fixed_thead = T)
```


<br>

<br>

## Cross-validation

In the multi-environment context, there are four types of cross-validation: CV1, CV2, CV0 and CV00. In CV1, we predict the performance of genotypes that were not tested in any environments, based on the performance of its relatives. In CV2, we predict the performance of genotypes that were tested in some environment, but were not tested in others. This is a common situation in plant breeding, and configure the sparse-test design. CV1 and CV2 are genotype-related. Conversely, CV0 and CV00 are related to the environments. In CV0, we predict how would be the performance of the tested genotypes in an untested environment. In CV00, we predict the performance of untested genotypes in untested environments. All the CV schemes have the same base: divide the data into a training set and a validation set by separating the data into *k* folds, then attributing *NA* for one fold and try to predict the data from this fold based on the others.

Here, we will illustrate only CV1 and CV2

### CV2

####  **1. Determine the number of folds and repetitions**

```{r echo=TRUE}
nfolds = 6
nrept = 3
```

By defining 6 folds, our data will be divided into 6 parts with 167 observations each.

<br>

#### **2. Match the order of the data and the rows of the SNP matrix by environment**

The order is decreasing or increasing (numeric or alphabetical) regarding the name of the genotypes.

```{r echo=TRUE}
pheno = pheno %>% arrange(LOC,GENO)
SNPs = SNPs[order(row.names(SNPs)),]
```

<br>

#### **3. Add a column indicating a number for each observation**

This will be useful to assign each observation for a fold, which will be the next step.

```{r echo=TRUE}
pheno$ID = factor(1:nrow(pheno))
```

<br>

#### **4. Folds assignment**

In this step, we will assign each observation to a fold. Bear in mind that for each repetition, the folds will comprise different observations. The purpose of the repetition is to make sure of the randomness of the assignment step. In this step, we will use the [cvTools](https://cran.r-project.org/web/packages/cvTools/cvTools.pdf) package [@cvTools]

```{r echo=TRUE}
set.seed(100)
sort<- list()
for(a in 1:nrept){
  for(j in 1:nfolds){
    folds <- cvFolds(nlevels(pheno$ID),type = "random", K = nfolds, R = 1)
    Sample <- cbind(folds$which,folds$subsets)
    cv <- split(Sample[,2], f=Sample[,1])
  }
  sort[[a]] <- cv  
}
rm(a, folds, j, cv, Sample)
```

<br>

#### **5. Cross-validation 2**

```{r echo=TRUE}
fold.list = sort
results = list()
Out = list()

ETA = list(list(X = E, model = "FIXED"),
           list(V = EVD_G$vectors, d = EVD_G$values, model = "RKHS"),
           list(V = EVD_GE$vectors, d = EVD_GE$values, model = "RKHS"))

for (z in 1:length(fold.list)) {
  for (i in 1:nfolds){
    
    # Training set
    train_data <- pheno 
    
    # Validation set
    train_data[train_data$ID %in% fold.list[[z]][[i]], "Y"] <- NA 
    
    # Fitting model 
    RKHS_M <- BGLR(y = train_data$Y, ETA = ETA, nIter = 30000, burnIn = 1000, 
                 thin = 5, verbose = F)
    
    # GEBV
    Pred <- data.frame(Yhat = RKHS_M$yHat, G = pheno$ID)
    rownames(Pred) <- rownames(pheno$GENO)
    
    # Predicted GEBV
    results[[i]] <- Pred[Pred[, "G"] %in% fold.list[[z]][[i]], ] 
    
    # Remove
    rm(RKHS_M, Pred, train_data)
  }
  
  GEBV <- do.call(rbind, results)
  GEBV <- GEBV[order(GEBV$G), ]
  
  # Log
  log <- all(GEBV$G == pheno$ID)
  
  # Results
  Out[[z]] <- data.frame(
    Rep = z,
    Log = log,
    Ac = round(cor(GEBV$Yhat, pheno$Y, use = "na.or.complete"), 3),
    MSPE = round(mean(((GEBV$Yhat - pheno$Y)^2), na.rm = T), 3),
    Slope = round(unname(lm(pheno$Y ~ GEBV$Yhat)$coefficients[2]),3)
  )
}

Out

```

Recall that object "Out" is divided by repetition. In the "Out" objects for each repetition, "Rep" is the number of the repetition, "Log" is a diagnostic indicating if the order of the predicted breeding values matches the order of the phenotypic data, "Ac" is the accuracy of prediction (correlation between the GEBV and phenotypes), "MSPE" is the mean square prediction error (the lower, the better), and "Slope" indicates the linearity between the GEBV and the phenotypes (the higher, the better).

### CV1

####  **1. Determine the number of folds and repetitions**

```{r echo=TRUE}
nfolds = 3
nrept = 6
```

The number of folds is different in this case. It will represent the number of genotypes which will have the value set to NA. Bear in mind that that all the genotypes in a fold will have their values deleted. We have 453 genotypes and defined $k = 3$, so each fold will have 151 genotypes. Therefore, for each repetition, we will predict the genomic breeding value of 151 genotypes based on the performance of 302 genotypes.

<br>

#### **2. Match the order of the data and the rows of the SNP matrix by environment**

```{r echo=TRUE}
pheno = pheno %>% arrange(GENO)
SNPs = SNPs[order(row.names(SNPs)),]
```

<br>

#### **3. Add a column indicating a number for each genotype**

This step is also different from CV2. Here, we will set a number for each genotype. Thus, we will substitute the ID column that we created in CV2 for a new ID column, appropriate for the CV1 scheme.

```{r echo=TRUE}
pheno = pheno %>% 
  select(-ID) %>% 
  left_join(data.frame(GENO = levels(pheno$GENO),
           ID = 1:nlevels(pheno$GENO)), by = "GENO") %>% 
  mutate(ID = as.factor(ID))

```

<br>

#### **4. Folds assignment**

In this step, we will assign each genotype to a fold.

```{r echo=TRUE}
set.seed(100)
sort<- list()
for(a in 1:nrept){
  for(j in 1:nfolds){
    folds <- cvFolds(nlevels(pheno$ID),type = "random", K = nfolds, R = 1)
    Sample <- cbind(folds$which,folds$subsets)
    cv <- split(Sample[,2], f=Sample[,1])
  }
  sort[[a]] <- cv  
}
rm(a, folds, j, cv, Sample)
```

<br>

#### **5. Cross-validation 2**

```{r echo=TRUE}
fold.list = sort
results = list()
Out = list()

ETA = list(list(X = E, model = "FIXED"),
           list(V = EVD_G$vectors, d = EVD_G$values, model = "RKHS"),
           list(V = EVD_GE$vectors, d = EVD_GE$values, model = "RKHS"))

for (z in 1:length(fold.list)) {
  for (i in 1:nfolds){
    
    # Training set
    train_data <- pheno 
    
    # Validation set
    train_data[train_data$ID %in% fold.list[[z]][[i]], "Y"] <- NA 
    
    # Fitting model 
    RKHS_M <- BGLR(y = train_data$Y, ETA = ETA, nIter = 30000, burnIn = 1000, 
                 thin = 5, verbose = F)
    
    # GEBV
    Pred <- data.frame(Yhat = RKHS_M$yHat, G = pheno$ID)
    rownames(Pred) <- rownames(pheno$GENO)
    
    # Predicted GEBV
    results[[i]] <- Pred[Pred[, "G"] %in% fold.list[[z]][[i]], ] 
    
    # Remove
    rm(RKHS_M, Pred, train_data)
  }
  
  GEBV <- do.call(rbind, results)
  GEBV <- GEBV[order(GEBV$G), ]
  
  # Log
  log <- all(GEBV$G == pheno$ID)
  
  # Results
  Out[[z]] <- data.frame(
    Rep = z,
    Log = log,
    Ac = round(cor(GEBV$Yhat, pheno$Y, use = "na.or.complete"), 3),
    MSPE = round(mean(((GEBV$Yhat - pheno$Y)^2), na.rm = T), 3),
    Slope = round(unname(lm(pheno$Y ~ GEBV$Yhat)$coefficients[2]),3)
  )
}

Out

```

Note that the accuracies are much lower than CV2. This is because CV1 is a more complex situation, and relies entirely on the information that is "borrowed" by the relatives. 


## References
